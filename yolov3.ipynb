{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "zy7ci484Xy4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNNBlock(nn.Module):\n",
        "  def __init__(self , in_channels , out_channels ,bn_act = True , **kwargs ):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(in_channels , out_channels ,bias = not bn_act , **kwargs)\n",
        "    self.bn = nn.BatchNorm2d(out_channels)\n",
        "    self.leaky = nn.LeakyReLU(0.1)\n",
        "    self.use_bn_act = bn_act\n",
        "  def forward(self , x):\n",
        "    if self.use_bn_act :\n",
        "      return self.leaky(self.bn(self.conv(x)))\n",
        "    else :\n",
        "      return self.leaky(self.conv(x))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2e-tUCPZbjhg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self , channels , dropout : int ,  num_repeats  , use_residual= False):\n",
        "    super().__init__()\n",
        "    self.layers = nn.ModuleList()\n",
        "    for repeat in range(num_repeats):\n",
        "      self.layers += [ nn.Sequential(\n",
        "          CNNBlock(channels , channels//2 , kernel_size = 1) ,\n",
        "          CNNBlock(channels//2 , channels , kernel_size = 3 , padding = 1)\n",
        "      )\n",
        "      ]\n",
        "    self.use_residual = use_residual\n",
        "    self.num_repeats = num_repeats\n",
        "\n",
        "\n",
        "  def forward(self , x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x) + x if self.use_residual else layer(x)\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "irCxAjsxZFvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScalePrediction(nn.Module):\n",
        "  def __init__(self , in_channels , num_classes) :\n",
        "    super().__init__()\n",
        "    self.pred = nn.Sequential(\n",
        "        CNNBlock(in_channels , 2* in_channels , kernel_size = 3 , padding = 1 ) ,\n",
        "        CNNBlock(2*in_channels , (num_classes + 5) * 3  , bn_act = False , kernel_size = 1) ,\n",
        "    ) #(B , channels , d1  , d2    ,)\n",
        "    self.num_classes = num_classes\n",
        "  def forward(self , x):\n",
        "    return (self.pred(x).reshape(x.shape[0] , 3 , self.num_classes + 5 , x.shape[2] , x.shape[3])).permute(0 , 1 , 3 , 4 ,2 ) #(N x 3 x 13 x 13 x (5 + num_of_classes))"
      ],
      "metadata": {
        "id": "3bqSd9tUcCHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List : [\"B\" , 1] #(blocks , num_of_repeats)\n",
        "config = [ #out_channel , kernel_size , stride\n",
        "    (32 , 3 , 1) ,\n",
        "    (64 , 3 , 2) ,\n",
        "    [\"B\" , 1] ,\n",
        "    (128 , 3 , 2) ,\n",
        "    [\"B\" , 2 ] ,\n",
        "    (256 , 3 , 2 ) ,\n",
        "    [\"B\" , 8] ,\n",
        "    (512 , 3 , 2) ,\n",
        "    [\"B\" , 8 ] ,\n",
        "    (1024 , 3 , 2) ,\n",
        "    [\"B\" , 4] ,\n",
        "    (512 , 1 , 1) ,\n",
        "    (1024 , 3 , 1),\n",
        "    \"S\" ,\n",
        "    (256 , 1 , 1) ,\n",
        "    \"U\" ,\n",
        "    (256 , 1 ,1 ) ,\n",
        "    (512 , 3 , 1) ,\n",
        "    \"S\" ,\n",
        "    (128 , 1 , 1) ,\n",
        "    (256 , 3 , 1) ,\n",
        "    \"S\" ,\n",
        "]"
      ],
      "metadata": {
        "id": "hopShlXfagSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqBNUJjDRWJO"
      },
      "outputs": [],
      "source": [
        "class Yolov3(nn.Module):\n",
        "  def __init__(self , in_channels = 3 , num_classes = 20 ):\n",
        "    super().__init__()\n",
        "    self.num_classes= num_classes\n",
        "    self.in_channels = in_channels\n",
        "    self.layers = self._create_conv_layers()\n",
        "  def forward(self , x):\n",
        "    outputs = []\n",
        "    route_connections = []\n",
        "    for layer in self.layers :\n",
        "      if isinstance(layer , ScalePrediction):\n",
        "        outputs.append(layer(x))\n",
        "        continue\n",
        "      x = layer(x)\n",
        "      if isinstance(layer , ResidualBlock) and layer.num_repeats == 8 :\n",
        "        route_connections.append(x)\n",
        "      elif isinstance(layer , nn.Upsample):\n",
        "        x = torch.cat([x , route_connections[-1]] , dim = -1)\n",
        "        route_connections.pop()\n",
        "    return outputs\n",
        "  def _create_conv_layers(self):\n",
        "    layers = nn.ModuleList()\n",
        "    in_channels = self.in_channels\n",
        "    for module in config :\n",
        "      if isinstance(module , tuple):\n",
        "        out_channels , kernel_size , stride = module\n",
        "        layers.append(CNNBlock(in_channels , out_channels , kernel_size = kernel_size , stride = stride , padding = 1 if kernel_size == 3 else 0 ,))\n",
        "        in_channels = out_channels\n",
        "      elif isinstance(module , list):\n",
        "        num_repeats = module[1]\n",
        "        layers.append(ResidualBlock(in_channels , 0.1 , num_repeats = num_repeats))\n",
        "      elif isinstance(module , str):\n",
        "        if module == \"S\" :\n",
        "          layers += [\n",
        "              ResidualBlock(in_channels , 0.1 ,use_residual = False , num_repeats = 1 ) ,\n",
        "              CNNBlock(in_channels , in_channels// 2 , kernel_size = 1   ) ,\n",
        "              ScalePrediction(in_channels//2  , num_classes = self.num_classes)\n",
        "          ]\n",
        "          in_channels = in_channels // 2\n",
        "      elif module == \"U\" :\n",
        "          layers.append(nn.Upsample(scale_factor = 2))\n",
        "          in_channels = in_channels * 3\n",
        "    return layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "-7lT7WUXlP9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 20\n",
        "IMAGE_SIZE = 416\n",
        "model = Yolov3(num_classes = num_classes )\n",
        "summary(model , (3 , 416 , 416))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZtqczcEjktkN",
        "outputId": "3bcd3e9a-5026-4c5b-b2a0-a5911f4a3dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 32, 416, 416]             864\n",
            "       BatchNorm2d-2         [-1, 32, 416, 416]              64\n",
            "         LeakyReLU-3         [-1, 32, 416, 416]               0\n",
            "          CNNBlock-4         [-1, 32, 416, 416]               0\n",
            "            Conv2d-5         [-1, 64, 208, 208]          18,432\n",
            "       BatchNorm2d-6         [-1, 64, 208, 208]             128\n",
            "         LeakyReLU-7         [-1, 64, 208, 208]               0\n",
            "          CNNBlock-8         [-1, 64, 208, 208]               0\n",
            "            Conv2d-9         [-1, 32, 208, 208]           2,048\n",
            "      BatchNorm2d-10         [-1, 32, 208, 208]              64\n",
            "        LeakyReLU-11         [-1, 32, 208, 208]               0\n",
            "         CNNBlock-12         [-1, 32, 208, 208]               0\n",
            "           Conv2d-13         [-1, 64, 208, 208]          18,432\n",
            "      BatchNorm2d-14         [-1, 64, 208, 208]             128\n",
            "        LeakyReLU-15         [-1, 64, 208, 208]               0\n",
            "         CNNBlock-16         [-1, 64, 208, 208]               0\n",
            "    ResidualBlock-17         [-1, 64, 208, 208]               0\n",
            "           Conv2d-18        [-1, 128, 104, 104]          73,728\n",
            "      BatchNorm2d-19        [-1, 128, 104, 104]             256\n",
            "        LeakyReLU-20        [-1, 128, 104, 104]               0\n",
            "         CNNBlock-21        [-1, 128, 104, 104]               0\n",
            "           Conv2d-22         [-1, 64, 104, 104]           8,192\n",
            "      BatchNorm2d-23         [-1, 64, 104, 104]             128\n",
            "        LeakyReLU-24         [-1, 64, 104, 104]               0\n",
            "         CNNBlock-25         [-1, 64, 104, 104]               0\n",
            "           Conv2d-26        [-1, 128, 104, 104]          73,728\n",
            "      BatchNorm2d-27        [-1, 128, 104, 104]             256\n",
            "        LeakyReLU-28        [-1, 128, 104, 104]               0\n",
            "         CNNBlock-29        [-1, 128, 104, 104]               0\n",
            "           Conv2d-30         [-1, 64, 104, 104]           8,192\n",
            "      BatchNorm2d-31         [-1, 64, 104, 104]             128\n",
            "        LeakyReLU-32         [-1, 64, 104, 104]               0\n",
            "         CNNBlock-33         [-1, 64, 104, 104]               0\n",
            "           Conv2d-34        [-1, 128, 104, 104]          73,728\n",
            "      BatchNorm2d-35        [-1, 128, 104, 104]             256\n",
            "        LeakyReLU-36        [-1, 128, 104, 104]               0\n",
            "         CNNBlock-37        [-1, 128, 104, 104]               0\n",
            "    ResidualBlock-38        [-1, 128, 104, 104]               0\n",
            "           Conv2d-39          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-40          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-41          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-42          [-1, 256, 52, 52]               0\n",
            "           Conv2d-43          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-44          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-45          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-46          [-1, 128, 52, 52]               0\n",
            "           Conv2d-47          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-48          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-49          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-50          [-1, 256, 52, 52]               0\n",
            "           Conv2d-51          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-52          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-53          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-54          [-1, 128, 52, 52]               0\n",
            "           Conv2d-55          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-56          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-57          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-58          [-1, 256, 52, 52]               0\n",
            "           Conv2d-59          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-60          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-61          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-62          [-1, 128, 52, 52]               0\n",
            "           Conv2d-63          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-64          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-65          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-66          [-1, 256, 52, 52]               0\n",
            "           Conv2d-67          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-68          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-69          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-70          [-1, 128, 52, 52]               0\n",
            "           Conv2d-71          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-72          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-73          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-74          [-1, 256, 52, 52]               0\n",
            "           Conv2d-75          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-76          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-77          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-78          [-1, 128, 52, 52]               0\n",
            "           Conv2d-79          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-80          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-81          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-82          [-1, 256, 52, 52]               0\n",
            "           Conv2d-83          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-84          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-85          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-86          [-1, 128, 52, 52]               0\n",
            "           Conv2d-87          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-88          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-89          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-90          [-1, 256, 52, 52]               0\n",
            "           Conv2d-91          [-1, 128, 52, 52]          32,768\n",
            "      BatchNorm2d-92          [-1, 128, 52, 52]             256\n",
            "        LeakyReLU-93          [-1, 128, 52, 52]               0\n",
            "         CNNBlock-94          [-1, 128, 52, 52]               0\n",
            "           Conv2d-95          [-1, 256, 52, 52]         294,912\n",
            "      BatchNorm2d-96          [-1, 256, 52, 52]             512\n",
            "        LeakyReLU-97          [-1, 256, 52, 52]               0\n",
            "         CNNBlock-98          [-1, 256, 52, 52]               0\n",
            "           Conv2d-99          [-1, 128, 52, 52]          32,768\n",
            "     BatchNorm2d-100          [-1, 128, 52, 52]             256\n",
            "       LeakyReLU-101          [-1, 128, 52, 52]               0\n",
            "        CNNBlock-102          [-1, 128, 52, 52]               0\n",
            "          Conv2d-103          [-1, 256, 52, 52]         294,912\n",
            "     BatchNorm2d-104          [-1, 256, 52, 52]             512\n",
            "       LeakyReLU-105          [-1, 256, 52, 52]               0\n",
            "        CNNBlock-106          [-1, 256, 52, 52]               0\n",
            "   ResidualBlock-107          [-1, 256, 52, 52]               0\n",
            "          Conv2d-108          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-109          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-110          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-111          [-1, 512, 26, 26]               0\n",
            "          Conv2d-112          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-113          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-114          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-115          [-1, 256, 26, 26]               0\n",
            "          Conv2d-116          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-117          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-118          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-119          [-1, 512, 26, 26]               0\n",
            "          Conv2d-120          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-121          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-122          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-123          [-1, 256, 26, 26]               0\n",
            "          Conv2d-124          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-125          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-126          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-127          [-1, 512, 26, 26]               0\n",
            "          Conv2d-128          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-129          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-130          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-131          [-1, 256, 26, 26]               0\n",
            "          Conv2d-132          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-133          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-134          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-135          [-1, 512, 26, 26]               0\n",
            "          Conv2d-136          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-137          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-138          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-139          [-1, 256, 26, 26]               0\n",
            "          Conv2d-140          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-141          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-142          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-143          [-1, 512, 26, 26]               0\n",
            "          Conv2d-144          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-145          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-146          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-147          [-1, 256, 26, 26]               0\n",
            "          Conv2d-148          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-149          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-150          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-151          [-1, 512, 26, 26]               0\n",
            "          Conv2d-152          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-153          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-154          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-155          [-1, 256, 26, 26]               0\n",
            "          Conv2d-156          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-157          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-158          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-159          [-1, 512, 26, 26]               0\n",
            "          Conv2d-160          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-161          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-162          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-163          [-1, 256, 26, 26]               0\n",
            "          Conv2d-164          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-165          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-166          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-167          [-1, 512, 26, 26]               0\n",
            "          Conv2d-168          [-1, 256, 26, 26]         131,072\n",
            "     BatchNorm2d-169          [-1, 256, 26, 26]             512\n",
            "       LeakyReLU-170          [-1, 256, 26, 26]               0\n",
            "        CNNBlock-171          [-1, 256, 26, 26]               0\n",
            "          Conv2d-172          [-1, 512, 26, 26]       1,179,648\n",
            "     BatchNorm2d-173          [-1, 512, 26, 26]           1,024\n",
            "       LeakyReLU-174          [-1, 512, 26, 26]               0\n",
            "        CNNBlock-175          [-1, 512, 26, 26]               0\n",
            "   ResidualBlock-176          [-1, 512, 26, 26]               0\n",
            "          Conv2d-177         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-178         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-179         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-180         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-181          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-182          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-183          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-184          [-1, 512, 13, 13]               0\n",
            "          Conv2d-185         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-186         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-187         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-188         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-189          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-190          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-191          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-192          [-1, 512, 13, 13]               0\n",
            "          Conv2d-193         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-194         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-195         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-196         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-197          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-198          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-199          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-200          [-1, 512, 13, 13]               0\n",
            "          Conv2d-201         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-202         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-203         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-204         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-205          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-206          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-207          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-208          [-1, 512, 13, 13]               0\n",
            "          Conv2d-209         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-210         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-211         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-212         [-1, 1024, 13, 13]               0\n",
            "   ResidualBlock-213         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-214          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-215          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-216          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-217          [-1, 512, 13, 13]               0\n",
            "          Conv2d-218         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-219         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-220         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-221         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-222          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-223          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-224          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-225          [-1, 512, 13, 13]               0\n",
            "          Conv2d-226         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-227         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-228         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-229         [-1, 1024, 13, 13]               0\n",
            "   ResidualBlock-230         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-231          [-1, 512, 13, 13]         524,288\n",
            "     BatchNorm2d-232          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-233          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-234          [-1, 512, 13, 13]               0\n",
            "          Conv2d-235         [-1, 1024, 13, 13]       4,718,592\n",
            "     BatchNorm2d-236         [-1, 1024, 13, 13]           2,048\n",
            "       LeakyReLU-237         [-1, 1024, 13, 13]               0\n",
            "        CNNBlock-238         [-1, 1024, 13, 13]               0\n",
            "          Conv2d-239           [-1, 75, 13, 13]          76,875\n",
            "       LeakyReLU-240           [-1, 75, 13, 13]               0\n",
            "        CNNBlock-241           [-1, 75, 13, 13]               0\n",
            " ScalePrediction-242        [-1, 3, 13, 13, 25]               0\n",
            "          Conv2d-243          [-1, 256, 13, 13]         131,072\n",
            "     BatchNorm2d-244          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-245          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-246          [-1, 256, 13, 13]               0\n",
            "          Conv2d-247          [-1, 256, 13, 13]          65,536\n",
            "     BatchNorm2d-248          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-249          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-250          [-1, 256, 13, 13]               0\n",
            "          Conv2d-251          [-1, 512, 13, 13]       1,179,648\n",
            "     BatchNorm2d-252          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-253          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-254          [-1, 512, 13, 13]               0\n",
            "          Conv2d-255          [-1, 256, 13, 13]         131,072\n",
            "     BatchNorm2d-256          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-257          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-258          [-1, 256, 13, 13]               0\n",
            "          Conv2d-259          [-1, 512, 13, 13]       1,179,648\n",
            "     BatchNorm2d-260          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-261          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-262          [-1, 512, 13, 13]               0\n",
            "   ResidualBlock-263          [-1, 512, 13, 13]               0\n",
            "          Conv2d-264          [-1, 256, 13, 13]         131,072\n",
            "     BatchNorm2d-265          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-266          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-267          [-1, 256, 13, 13]               0\n",
            "          Conv2d-268          [-1, 512, 13, 13]       1,179,648\n",
            "     BatchNorm2d-269          [-1, 512, 13, 13]           1,024\n",
            "       LeakyReLU-270          [-1, 512, 13, 13]               0\n",
            "        CNNBlock-271          [-1, 512, 13, 13]               0\n",
            "          Conv2d-272           [-1, 75, 13, 13]          38,475\n",
            "       LeakyReLU-273           [-1, 75, 13, 13]               0\n",
            "        CNNBlock-274           [-1, 75, 13, 13]               0\n",
            " ScalePrediction-275        [-1, 3, 13, 13, 25]               0\n",
            "          Conv2d-276          [-1, 128, 13, 13]          32,768\n",
            "     BatchNorm2d-277          [-1, 128, 13, 13]             256\n",
            "       LeakyReLU-278          [-1, 128, 13, 13]               0\n",
            "        CNNBlock-279          [-1, 128, 13, 13]               0\n",
            "          Conv2d-280          [-1, 256, 13, 13]         294,912\n",
            "     BatchNorm2d-281          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-282          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-283          [-1, 256, 13, 13]               0\n",
            "          Conv2d-284          [-1, 128, 13, 13]          32,768\n",
            "     BatchNorm2d-285          [-1, 128, 13, 13]             256\n",
            "       LeakyReLU-286          [-1, 128, 13, 13]               0\n",
            "        CNNBlock-287          [-1, 128, 13, 13]               0\n",
            "          Conv2d-288          [-1, 256, 13, 13]         294,912\n",
            "     BatchNorm2d-289          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-290          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-291          [-1, 256, 13, 13]               0\n",
            "   ResidualBlock-292          [-1, 256, 13, 13]               0\n",
            "          Conv2d-293          [-1, 128, 13, 13]          32,768\n",
            "     BatchNorm2d-294          [-1, 128, 13, 13]             256\n",
            "       LeakyReLU-295          [-1, 128, 13, 13]               0\n",
            "        CNNBlock-296          [-1, 128, 13, 13]               0\n",
            "          Conv2d-297          [-1, 256, 13, 13]         294,912\n",
            "     BatchNorm2d-298          [-1, 256, 13, 13]             512\n",
            "       LeakyReLU-299          [-1, 256, 13, 13]               0\n",
            "        CNNBlock-300          [-1, 256, 13, 13]               0\n",
            "          Conv2d-301           [-1, 75, 13, 13]          19,275\n",
            "       LeakyReLU-302           [-1, 75, 13, 13]               0\n",
            "        CNNBlock-303           [-1, 75, 13, 13]               0\n",
            " ScalePrediction-304        [-1, 3, 13, 13, 25]               0\n",
            "================================================================\n",
            "Total params: 61,445,569\n",
            "Trainable params: 61,445,569\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.98\n",
            "Forward/backward pass size (MB): 1085.47\n",
            "Params size (MB): 234.40\n",
            "Estimated Total Size (MB): 1321.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aladdinpersson/pascalvoc-yolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2xJFLNPjuAT",
        "outputId": "a52297f4-70f8-431c-99fb-c12adf4f96bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/aladdinpersson/pascalvoc-yolo\n",
            "License(s): unknown\n",
            "pascalvoc-yolo.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/pascalvoc-yolo.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mLj10vRWtdEI",
        "outputId": "8c2917e6-8987-42b3-df7c-e3233871c5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/pascalvoc-yolo.zip\n",
            "replace 100examples.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from PIL import Image , ImageFile\n",
        "from torch.utils.data import Dataset , DataLoader"
      ],
      "metadata": {
        "id": "fb99JY6It6Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iou(box1 , box2):\n",
        "  x_left  = torch.max(box1[... , 1 ] , box2[... , 1 ])\n",
        "  y_below = torch.max(box1[... , 2] , box2[... , 2])\n",
        "  x_right = torch.min(box1[... , 1] + box1[... , 3] * 0.5 , box2[... , 1] + box2[... , 3] * 0.5)\n",
        "  y_above = torch.min(box1[... , 2] + box1[... , 4] * 0.5 , box2[... , 2] + box2[... , 4] * 0.5)\n",
        "  area_o_int = (x_right - x_left).clamp(0) * (y_above - y_below).clamp(0)\n",
        "  area_total = box1[...,3] * box1[... , 4] + box2[... , 3] * box2[... , 4] - area_o_int\n",
        "  iou = area_o_int / (area_total)\n",
        "  return iou"
      ],
      "metadata": {
        "id": "n5u1AroZuc-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "metadata": {
        "id": "Wy5bgwrivD3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install svn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS-niYX5JVTf",
        "outputId": "95abeaca-b907-4431-8294-6d86e2f9273e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting svn\n",
            "  Downloading svn-1.0.1.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from svn) (2.8.2)\n",
            "Collecting nose (from svn)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.2->svn) (1.16.0)\n",
            "Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: svn\n",
            "  Building wheel for svn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for svn: filename=svn-1.0.1-py2.py3-none-any.whl size=16037 sha256=b030a1d83725a0b01a5dacdef082a94423a653e0b7d842e82d6f647160c478f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/b1/38/b7c80242ad28c7cc6b8f1de515dc16d0cf654b96e4448034d4\n",
            "Successfully built svn\n",
            "Installing collected packages: nose, svn\n",
            "Successfully installed nose-1.3.7 svn-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install subversion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVd4KsIgiBkJ",
        "outputId": "34399d7e-80b8-415f-9a37-a385e6c321a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1 libutf8proc2\n",
            "Suggested packages:\n",
            "  db5.3-util libapache2-mod-svn subversion-tools\n",
            "The following NEW packages will be installed:\n",
            "  libapr1 libaprutil1 libserf-1-1 libsvn1 libutf8proc2 subversion\n",
            "0 upgraded, 6 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 2,672 kB of archives.\n",
            "After this operation, 10.5 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libapr1 amd64 1.7.0-8ubuntu0.22.04.1 [108 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libaprutil1 amd64 1.6.1-5ubuntu4.22.04.2 [92.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libserf-1-1 amd64 1.3.9-10ubuntu2 [50.0 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libutf8proc2 amd64 2.7.0-3 [73.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsvn1 amd64 1.14.1-3ubuntu0.22.04.1 [1,387 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 subversion amd64 1.14.1-3ubuntu0.22.04.1 [960 kB]\n",
            "Fetched 2,672 kB in 1s (1,955 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libapr1:amd64.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libapr1_1.7.0-8ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libapr1:amd64 (1.7.0-8ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package libaprutil1:amd64.\n",
            "Preparing to unpack .../1-libaprutil1_1.6.1-5ubuntu4.22.04.2_amd64.deb ...\n",
            "Unpacking libaprutil1:amd64 (1.6.1-5ubuntu4.22.04.2) ...\n",
            "Selecting previously unselected package libserf-1-1:amd64.\n",
            "Preparing to unpack .../2-libserf-1-1_1.3.9-10ubuntu2_amd64.deb ...\n",
            "Unpacking libserf-1-1:amd64 (1.3.9-10ubuntu2) ...\n",
            "Selecting previously unselected package libutf8proc2:amd64.\n",
            "Preparing to unpack .../3-libutf8proc2_2.7.0-3_amd64.deb ...\n",
            "Unpacking libutf8proc2:amd64 (2.7.0-3) ...\n",
            "Selecting previously unselected package libsvn1:amd64.\n",
            "Preparing to unpack .../4-libsvn1_1.14.1-3ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking libsvn1:amd64 (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package subversion.\n",
            "Preparing to unpack .../5-subversion_1.14.1-3ubuntu0.22.04.1_amd64.deb ...\n",
            "Unpacking subversion (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Setting up libutf8proc2:amd64 (2.7.0-3) ...\n",
            "Setting up libapr1:amd64 (1.7.0-8ubuntu0.22.04.1) ...\n",
            "Setting up libaprutil1:amd64 (1.6.1-5ubuntu4.22.04.2) ...\n",
            "Setting up libserf-1-1:amd64 (1.3.9-10ubuntu2) ...\n",
            "Setting up libsvn1:amd64 (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Setting up subversion (1.14.1-3ubuntu0.22.04.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class YOLODataset(Dataset):\n",
        "  def __init__(self\n",
        "               , csv_file , img_dir , label_dir , anchors  , image_size = 416 , S = [13 , 26 , 52] , C = 20 , transform  = None):\n",
        "    self.annotations = pd.read_csv(csv_file)\n",
        "    self.img_dir = img_dir\n",
        "    self.label_dir = label_dir\n",
        "    self.transform = transform\n",
        "    self.S = S\n",
        "    self.anchors = torch.tensor(anchors[0] + anchors[1] + anchors[2]) # for all 3 scales\n",
        "    self.num_anchors = self.anchors.shape[0]\n",
        "    self.num_anchors_per_scale = self.num_anchors // 3\n",
        "    self.C = C\n",
        "    self.ignore_iou_thresh = 0.5\n",
        "  def __len__(self):\n",
        "    return len(self.annotations)\n",
        "  def __getitem__(self , index):\n",
        "    label_path = os.path.join(self.label_dir , self.annotations.iloc[index , 1]  )\n",
        "    image_path = os.path.join(self.image_dir , self.annotations.iloc[index , 0])\n",
        "    bboxes = np.roll(np.loadtxt(fname = label_path , delimiter = \" \" , ndmin = 2 ).tolist(), 4 , axis = 1 ).tolist() # [class , x , y ,w , h] --> [x , y ,w , h ,class , ]\n",
        "    img_path = os.path.join(self.img_dir , self.annotations.iloc[index , 0])\n",
        "    image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "    if self.transform :\n",
        "      augmentations = self.transform(image = image , bboxes = bboxes)\n",
        "      image  = augmentations[\"image\"]\n",
        "      bboxes = augmentations[\"bboxes\"]\n",
        "    target = [torch.zeros((self.num_anchors // 3 , S , S , 6 )) for S in self.S]  # assume same no. of object at each scale , 6-> [p_o  , x , y , w , h , c]\n",
        "    for box in bboxes :\n",
        "      iou_anchors = iou(torch.tensor(box[:4]) , self.anchors)\n",
        "      anchor_indices = iou_anchors.argsort(descending = True , dim = 0 )\n",
        "      x , y , width , height , class_label = box\n",
        "      has_anchor = [False , False , False]\n",
        "\n",
        "      for anchor_idx in anchor_indices :\n",
        "        scale_idx = anchor_idx // (self.num_anchors_per_scale)\n",
        "        anchor_on_scale = anchor_idx %  self.num_anchors_per_scale\n",
        "        S = self.S[scale_idx]\n",
        "        i , j = int(S*y) , int(S * x)\n",
        "\n",
        "        anchor_taken = target[scale_idx][anchor_on_scale , i , j ,0]\n",
        "        if not anchor_taken and not has_anchor[scale_idx]:\n",
        "          target[scale_idx][anchor_on_scale , i , j , 0] = 1\n",
        "          x_cell = S*x - j\n",
        "          y_cell = S* y - i\n",
        "          width_cell, height_cell = (width * S , height * S)\n",
        "          box_coordinates = torch.tensor(\n",
        "              [x_cell , y_cell , width_cell , height_cell]\n",
        "          )\n",
        "          target[scale_idx][anchor_on_scale , i , j , 1:5] = box_coordinates\n",
        "          target[scale_idx][anchor_on_scale , i , j , 5] = int(class_label)\n",
        "        elif not anchor_taken and iou_anchors[anchor_idx] > self.ignore_iou_threshold :\n",
        "          target[scale_idx][anchor_on_scale , i , j, 0] = -1\n",
        "    return image , target"
      ],
      "metadata": {
        "id": "i_Sr7I7Uvk3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class YoloLoss(nn.Module):\n",
        "  def __init__(self ):\n",
        "    super().__init__()\n",
        "    self.mse = nn.MSELoss()\n",
        "    self.bce = nn.BCEWithLogitsLoss()\n",
        "    self.entropy = nn.CrossEntropy()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    #constants\n",
        "    self.lambda_class = 1\n",
        "    self.lambda_nooobj = 10\n",
        "    self.lambda_obj = 1\n",
        "    self.lambda_box = 1\n",
        "  def forward(self , predictions , target , anchors):\n",
        "    obj = target[...  , 0] == 1\n",
        "    noobj = target[... ,0] == 0\n",
        "\n",
        "    #No object loss\n",
        "    no_object_loss = self.bce(\n",
        "        predictions[... , 0:1][noobj] , target[... , 0:1][noobj]\n",
        "    )\n",
        "\n",
        "    # object loss\n",
        "    anchors = anchors.reshape(1 , 3 , 1 , 1 ,2) # 3 * 2\n",
        "    box_pred = torch.cat([self.sigmoid(predictions[... , 1:3]) , torch.exp(predictions[... , 3 : 5] * anchors)] , dim = -1)\n",
        "    ious\n"
      ],
      "metadata": {
        "id": "fW3W27YXBquv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O88kTD-I27SE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}